{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.BulkOperationBase = exports.FindOperators = exports.MongoBulkWriteError = exports.mergeBatchResults = exports.WriteError = exports.WriteConcernError = exports.BulkWriteResult = exports.Batch = exports.BatchType = void 0;\nconst bson_1 = require(\"../bson\");\nconst error_1 = require(\"../error\");\nconst delete_1 = require(\"../operations/delete\");\nconst execute_operation_1 = require(\"../operations/execute_operation\");\nconst insert_1 = require(\"../operations/insert\");\nconst operation_1 = require(\"../operations/operation\");\nconst update_1 = require(\"../operations/update\");\nconst utils_1 = require(\"../utils\");\nconst write_concern_1 = require(\"../write_concern\");\n/** @internal */\nconst kServerError = Symbol('serverError');\n/** @public */\nexports.BatchType = Object.freeze({\n  INSERT: 1,\n  UPDATE: 2,\n  DELETE: 3\n});\n/**\n * Keeps the state of a unordered batch so we can rewrite the results\n * correctly after command execution\n *\n * @public\n */\nclass Batch {\n  constructor(batchType, originalZeroIndex) {\n    this.originalZeroIndex = originalZeroIndex;\n    this.currentIndex = 0;\n    this.originalIndexes = [];\n    this.batchType = batchType;\n    this.operations = [];\n    this.size = 0;\n    this.sizeBytes = 0;\n  }\n}\nexports.Batch = Batch;\n/**\n * @public\n * The result of a bulk write.\n */\nclass BulkWriteResult {\n  /**\n   * Create a new BulkWriteResult instance\n   * @internal\n   */\n  constructor(bulkResult) {\n    this.result = bulkResult;\n  }\n  /** Number of documents inserted. */\n  get insertedCount() {\n    var _a;\n    return (_a = this.result.nInserted) !== null && _a !== void 0 ? _a : 0;\n  }\n  /** Number of documents matched for update. */\n  get matchedCount() {\n    var _a;\n    return (_a = this.result.nMatched) !== null && _a !== void 0 ? _a : 0;\n  }\n  /** Number of documents modified. */\n  get modifiedCount() {\n    var _a;\n    return (_a = this.result.nModified) !== null && _a !== void 0 ? _a : 0;\n  }\n  /** Number of documents deleted. */\n  get deletedCount() {\n    var _a;\n    return (_a = this.result.nRemoved) !== null && _a !== void 0 ? _a : 0;\n  }\n  /** Number of documents upserted. */\n  get upsertedCount() {\n    var _a;\n    return (_a = this.result.upserted.length) !== null && _a !== void 0 ? _a : 0;\n  }\n  /** Upserted document generated Id's, hash key is the index of the originating operation */\n  get upsertedIds() {\n    var _a;\n    const upserted = {};\n    for (const doc of (_a = this.result.upserted) !== null && _a !== void 0 ? _a : []) {\n      upserted[doc.index] = doc._id;\n    }\n    return upserted;\n  }\n  /** Inserted document generated Id's, hash key is the index of the originating operation */\n  get insertedIds() {\n    var _a;\n    const inserted = {};\n    for (const doc of (_a = this.result.insertedIds) !== null && _a !== void 0 ? _a : []) {\n      inserted[doc.index] = doc._id;\n    }\n    return inserted;\n  }\n  /** Evaluates to true if the bulk operation correctly executes */\n  get ok() {\n    return this.result.ok;\n  }\n  /** The number of inserted documents */\n  get nInserted() {\n    return this.result.nInserted;\n  }\n  /** Number of upserted documents */\n  get nUpserted() {\n    return this.result.nUpserted;\n  }\n  /** Number of matched documents */\n  get nMatched() {\n    return this.result.nMatched;\n  }\n  /** Number of documents updated physically on disk */\n  get nModified() {\n    return this.result.nModified;\n  }\n  /** Number of removed documents */\n  get nRemoved() {\n    return this.result.nRemoved;\n  }\n  /** Returns an array of all inserted ids */\n  getInsertedIds() {\n    return this.result.insertedIds;\n  }\n  /** Returns an array of all upserted ids */\n  getUpsertedIds() {\n    return this.result.upserted;\n  }\n  /** Returns the upserted id at the given index */\n  getUpsertedIdAt(index) {\n    return this.result.upserted[index];\n  }\n  /** Returns raw internal result */\n  getRawResponse() {\n    return this.result;\n  }\n  /** Returns true if the bulk operation contains a write error */\n  hasWriteErrors() {\n    return this.result.writeErrors.length > 0;\n  }\n  /** Returns the number of write errors off the bulk operation */\n  getWriteErrorCount() {\n    return this.result.writeErrors.length;\n  }\n  /** Returns a specific write error object */\n  getWriteErrorAt(index) {\n    return index < this.result.writeErrors.length ? this.result.writeErrors[index] : undefined;\n  }\n  /** Retrieve all write errors */\n  getWriteErrors() {\n    return this.result.writeErrors;\n  }\n  /**\n   * Retrieve lastOp if available\n   *\n   * @deprecated Will be removed in 5.0\n   */\n  getLastOp() {\n    return this.result.opTime;\n  }\n  /** Retrieve the write concern error if one exists */\n  getWriteConcernError() {\n    if (this.result.writeConcernErrors.length === 0) {\n      return;\n    } else if (this.result.writeConcernErrors.length === 1) {\n      // Return the error\n      return this.result.writeConcernErrors[0];\n    } else {\n      // Combine the errors\n      let errmsg = '';\n      for (let i = 0; i < this.result.writeConcernErrors.length; i++) {\n        const err = this.result.writeConcernErrors[i];\n        errmsg = errmsg + err.errmsg;\n        // TODO: Something better\n        if (i === 0) errmsg = errmsg + ' and ';\n      }\n      return new WriteConcernError({\n        errmsg,\n        code: error_1.MONGODB_ERROR_CODES.WriteConcernFailed\n      });\n    }\n  }\n  /* @deprecated Will be removed in 5.0 release */\n  toJSON() {\n    return this.result;\n  }\n  toString() {\n    return `BulkWriteResult(${this.toJSON()})`;\n  }\n  isOk() {\n    return this.result.ok === 1;\n  }\n}\nexports.BulkWriteResult = BulkWriteResult;\n/**\n * An error representing a failure by the server to apply the requested write concern to the bulk operation.\n * @public\n * @category Error\n */\nclass WriteConcernError {\n  constructor(error) {\n    this[kServerError] = error;\n  }\n  /** Write concern error code. */\n  get code() {\n    return this[kServerError].code;\n  }\n  /** Write concern error message. */\n  get errmsg() {\n    return this[kServerError].errmsg;\n  }\n  /** Write concern error info. */\n  get errInfo() {\n    return this[kServerError].errInfo;\n  }\n  /** @deprecated The `err` prop that contained a MongoServerError has been deprecated. */\n  get err() {\n    return this[kServerError];\n  }\n  toJSON() {\n    return this[kServerError];\n  }\n  toString() {\n    return `WriteConcernError(${this.errmsg})`;\n  }\n}\nexports.WriteConcernError = WriteConcernError;\n/**\n * An error that occurred during a BulkWrite on the server.\n * @public\n * @category Error\n */\nclass WriteError {\n  constructor(err) {\n    this.err = err;\n  }\n  /** WriteError code. */\n  get code() {\n    return this.err.code;\n  }\n  /** WriteError original bulk operation index. */\n  get index() {\n    return this.err.index;\n  }\n  /** WriteError message. */\n  get errmsg() {\n    return this.err.errmsg;\n  }\n  /** WriteError details. */\n  get errInfo() {\n    return this.err.errInfo;\n  }\n  /** Returns the underlying operation that caused the error */\n  getOperation() {\n    return this.err.op;\n  }\n  toJSON() {\n    return {\n      code: this.err.code,\n      index: this.err.index,\n      errmsg: this.err.errmsg,\n      op: this.err.op\n    };\n  }\n  toString() {\n    return `WriteError(${JSON.stringify(this.toJSON())})`;\n  }\n}\nexports.WriteError = WriteError;\n/** Converts the number to a Long or returns it. */\nfunction longOrConvert(value) {\n  // TODO(NODE-2674): Preserve int64 sent from MongoDB\n  return typeof value === 'number' ? bson_1.Long.fromNumber(value) : value;\n}\n/** Merges results into shared data structure */\nfunction mergeBatchResults(batch, bulkResult, err, result) {\n  // If we have an error set the result to be the err object\n  if (err) {\n    result = err;\n  } else if (result && result.result) {\n    result = result.result;\n  }\n  if (result == null) {\n    return;\n  }\n  // Do we have a top level error stop processing and return\n  if (result.ok === 0 && bulkResult.ok === 1) {\n    bulkResult.ok = 0;\n    const writeError = {\n      index: 0,\n      code: result.code || 0,\n      errmsg: result.message,\n      errInfo: result.errInfo,\n      op: batch.operations[0]\n    };\n    bulkResult.writeErrors.push(new WriteError(writeError));\n    return;\n  } else if (result.ok === 0 && bulkResult.ok === 0) {\n    return;\n  }\n  // The server write command specification states that lastOp is an optional\n  // mongod only field that has a type of timestamp. Across various scarce specs\n  // where opTime is mentioned, it is an \"opaque\" object that can have a \"ts\" and\n  // \"t\" field with Timestamp and Long as their types respectively.\n  // The \"lastOp\" field of the bulk write result is never mentioned in the driver\n  // specifications or the bulk write spec, so we should probably just keep its\n  // value consistent since it seems to vary.\n  // See: https://github.com/mongodb/specifications/blob/master/source/driver-bulk-update.rst#results-object\n  if (result.opTime || result.lastOp) {\n    let opTime = result.lastOp || result.opTime;\n    // If the opTime is a Timestamp, convert it to a consistent format to be\n    // able to compare easily. Converting to the object from a timestamp is\n    // much more straightforward than the other direction.\n    if (opTime._bsontype === 'Timestamp') {\n      opTime = {\n        ts: opTime,\n        t: bson_1.Long.ZERO\n      };\n    }\n    // If there's no lastOp, just set it.\n    if (!bulkResult.opTime) {\n      bulkResult.opTime = opTime;\n    } else {\n      // First compare the ts values and set if the opTimeTS value is greater.\n      const lastOpTS = longOrConvert(bulkResult.opTime.ts);\n      const opTimeTS = longOrConvert(opTime.ts);\n      if (opTimeTS.greaterThan(lastOpTS)) {\n        bulkResult.opTime = opTime;\n      } else if (opTimeTS.equals(lastOpTS)) {\n        // If the ts values are equal, then compare using the t values.\n        const lastOpT = longOrConvert(bulkResult.opTime.t);\n        const opTimeT = longOrConvert(opTime.t);\n        if (opTimeT.greaterThan(lastOpT)) {\n          bulkResult.opTime = opTime;\n        }\n      }\n    }\n  }\n  // If we have an insert Batch type\n  if (isInsertBatch(batch) && result.n) {\n    bulkResult.nInserted = bulkResult.nInserted + result.n;\n  }\n  // If we have an insert Batch type\n  if (isDeleteBatch(batch) && result.n) {\n    bulkResult.nRemoved = bulkResult.nRemoved + result.n;\n  }\n  let nUpserted = 0;\n  // We have an array of upserted values, we need to rewrite the indexes\n  if (Array.isArray(result.upserted)) {\n    nUpserted = result.upserted.length;\n    for (let i = 0; i < result.upserted.length; i++) {\n      bulkResult.upserted.push({\n        index: result.upserted[i].index + batch.originalZeroIndex,\n        _id: result.upserted[i]._id\n      });\n    }\n  } else if (result.upserted) {\n    nUpserted = 1;\n    bulkResult.upserted.push({\n      index: batch.originalZeroIndex,\n      _id: result.upserted\n    });\n  }\n  // If we have an update Batch type\n  if (isUpdateBatch(batch) && result.n) {\n    const nModified = result.nModified;\n    bulkResult.nUpserted = bulkResult.nUpserted + nUpserted;\n    bulkResult.nMatched = bulkResult.nMatched + (result.n - nUpserted);\n    if (typeof nModified === 'number') {\n      bulkResult.nModified = bulkResult.nModified + nModified;\n    } else {\n      bulkResult.nModified = 0;\n    }\n  }\n  if (Array.isArray(result.writeErrors)) {\n    for (let i = 0; i < result.writeErrors.length; i++) {\n      const writeError = {\n        index: batch.originalIndexes[result.writeErrors[i].index],\n        code: result.writeErrors[i].code,\n        errmsg: result.writeErrors[i].errmsg,\n        errInfo: result.writeErrors[i].errInfo,\n        op: batch.operations[result.writeErrors[i].index]\n      };\n      bulkResult.writeErrors.push(new WriteError(writeError));\n    }\n  }\n  if (result.writeConcernError) {\n    bulkResult.writeConcernErrors.push(new WriteConcernError(result.writeConcernError));\n  }\n}\nexports.mergeBatchResults = mergeBatchResults;\nfunction executeCommands(bulkOperation, options, callback) {\n  if (bulkOperation.s.batches.length === 0) {\n    return callback(undefined, new BulkWriteResult(bulkOperation.s.bulkResult));\n  }\n  const batch = bulkOperation.s.batches.shift();\n  function resultHandler(err, result) {\n    // Error is a driver related error not a bulk op error, return early\n    if (err && 'message' in err && !(err instanceof error_1.MongoWriteConcernError)) {\n      return callback(new MongoBulkWriteError(err, new BulkWriteResult(bulkOperation.s.bulkResult)));\n    }\n    if (err instanceof error_1.MongoWriteConcernError) {\n      return handleMongoWriteConcernError(batch, bulkOperation.s.bulkResult, err, callback);\n    }\n    // Merge the results together\n    const writeResult = new BulkWriteResult(bulkOperation.s.bulkResult);\n    const mergeResult = mergeBatchResults(batch, bulkOperation.s.bulkResult, err, result);\n    if (mergeResult != null) {\n      return callback(undefined, writeResult);\n    }\n    if (bulkOperation.handleWriteError(callback, writeResult)) return;\n    // Execute the next command in line\n    executeCommands(bulkOperation, options, callback);\n  }\n  const finalOptions = (0, utils_1.resolveOptions)(bulkOperation, {\n    ...options,\n    ordered: bulkOperation.isOrdered\n  });\n  if (finalOptions.bypassDocumentValidation !== true) {\n    delete finalOptions.bypassDocumentValidation;\n  }\n  // Set an operationIf if provided\n  if (bulkOperation.operationId) {\n    resultHandler.operationId = bulkOperation.operationId;\n  }\n  // Is the bypassDocumentValidation options specific\n  if (bulkOperation.s.bypassDocumentValidation === true) {\n    finalOptions.bypassDocumentValidation = true;\n  }\n  // Is the checkKeys option disabled\n  if (bulkOperation.s.checkKeys === false) {\n    finalOptions.checkKeys = false;\n  }\n  if (finalOptions.retryWrites) {\n    if (isUpdateBatch(batch)) {\n      finalOptions.retryWrites = finalOptions.retryWrites && !batch.operations.some(op => op.multi);\n    }\n    if (isDeleteBatch(batch)) {\n      finalOptions.retryWrites = finalOptions.retryWrites && !batch.operations.some(op => op.limit === 0);\n    }\n  }\n  try {\n    if (isInsertBatch(batch)) {\n      (0, execute_operation_1.executeOperation)(bulkOperation.s.collection.s.db.s.client, new insert_1.InsertOperation(bulkOperation.s.namespace, batch.operations, finalOptions), resultHandler);\n    } else if (isUpdateBatch(batch)) {\n      (0, execute_operation_1.executeOperation)(bulkOperation.s.collection.s.db.s.client, new update_1.UpdateOperation(bulkOperation.s.namespace, batch.operations, finalOptions), resultHandler);\n    } else if (isDeleteBatch(batch)) {\n      (0, execute_operation_1.executeOperation)(bulkOperation.s.collection.s.db.s.client, new delete_1.DeleteOperation(bulkOperation.s.namespace, batch.operations, finalOptions), resultHandler);\n    }\n  } catch (err) {\n    // Force top level error\n    err.ok = 0;\n    // Merge top level error and return\n    mergeBatchResults(batch, bulkOperation.s.bulkResult, err, undefined);\n    callback();\n  }\n}\nfunction handleMongoWriteConcernError(batch, bulkResult, err, callback) {\n  var _a, _b;\n  mergeBatchResults(batch, bulkResult, undefined, err.result);\n  callback(new MongoBulkWriteError({\n    message: (_a = err.result) === null || _a === void 0 ? void 0 : _a.writeConcernError.errmsg,\n    code: (_b = err.result) === null || _b === void 0 ? void 0 : _b.writeConcernError.result\n  }, new BulkWriteResult(bulkResult)));\n}\n/**\n * An error indicating an unsuccessful Bulk Write\n * @public\n * @category Error\n */\nclass MongoBulkWriteError extends error_1.MongoServerError {\n  /** Creates a new MongoBulkWriteError */\n  constructor(error, result) {\n    var _a;\n    super(error);\n    this.writeErrors = [];\n    if (error instanceof WriteConcernError) this.err = error;else if (!(error instanceof Error)) {\n      this.message = error.message;\n      this.code = error.code;\n      this.writeErrors = (_a = error.writeErrors) !== null && _a !== void 0 ? _a : [];\n    }\n    this.result = result;\n    Object.assign(this, error);\n  }\n  get name() {\n    return 'MongoBulkWriteError';\n  }\n  /** Number of documents inserted. */\n  get insertedCount() {\n    return this.result.insertedCount;\n  }\n  /** Number of documents matched for update. */\n  get matchedCount() {\n    return this.result.matchedCount;\n  }\n  /** Number of documents modified. */\n  get modifiedCount() {\n    return this.result.modifiedCount;\n  }\n  /** Number of documents deleted. */\n  get deletedCount() {\n    return this.result.deletedCount;\n  }\n  /** Number of documents upserted. */\n  get upsertedCount() {\n    return this.result.upsertedCount;\n  }\n  /** Inserted document generated Id's, hash key is the index of the originating operation */\n  get insertedIds() {\n    return this.result.insertedIds;\n  }\n  /** Upserted document generated Id's, hash key is the index of the originating operation */\n  get upsertedIds() {\n    return this.result.upsertedIds;\n  }\n}\nexports.MongoBulkWriteError = MongoBulkWriteError;\n/**\n * A builder object that is returned from {@link BulkOperationBase#find}.\n * Is used to build a write operation that involves a query filter.\n *\n * @public\n */\nclass FindOperators {\n  /**\n   * Creates a new FindOperators object.\n   * @internal\n   */\n  constructor(bulkOperation) {\n    this.bulkOperation = bulkOperation;\n  }\n  /** Add a multiple update operation to the bulk operation */\n  update(updateDocument) {\n    const currentOp = buildCurrentOp(this.bulkOperation);\n    return this.bulkOperation.addToOperationsList(exports.BatchType.UPDATE, (0, update_1.makeUpdateStatement)(currentOp.selector, updateDocument, {\n      ...currentOp,\n      multi: true\n    }));\n  }\n  /** Add a single update operation to the bulk operation */\n  updateOne(updateDocument) {\n    if (!(0, utils_1.hasAtomicOperators)(updateDocument)) {\n      throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n    }\n    const currentOp = buildCurrentOp(this.bulkOperation);\n    return this.bulkOperation.addToOperationsList(exports.BatchType.UPDATE, (0, update_1.makeUpdateStatement)(currentOp.selector, updateDocument, {\n      ...currentOp,\n      multi: false\n    }));\n  }\n  /** Add a replace one operation to the bulk operation */\n  replaceOne(replacement) {\n    if ((0, utils_1.hasAtomicOperators)(replacement)) {\n      throw new error_1.MongoInvalidArgumentError('Replacement document must not use atomic operators');\n    }\n    const currentOp = buildCurrentOp(this.bulkOperation);\n    return this.bulkOperation.addToOperationsList(exports.BatchType.UPDATE, (0, update_1.makeUpdateStatement)(currentOp.selector, replacement, {\n      ...currentOp,\n      multi: false\n    }));\n  }\n  /** Add a delete one operation to the bulk operation */\n  deleteOne() {\n    const currentOp = buildCurrentOp(this.bulkOperation);\n    return this.bulkOperation.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(currentOp.selector, {\n      ...currentOp,\n      limit: 1\n    }));\n  }\n  /** Add a delete many operation to the bulk operation */\n  delete() {\n    const currentOp = buildCurrentOp(this.bulkOperation);\n    return this.bulkOperation.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(currentOp.selector, {\n      ...currentOp,\n      limit: 0\n    }));\n  }\n  /** Upsert modifier for update bulk operation, noting that this operation is an upsert. */\n  upsert() {\n    if (!this.bulkOperation.s.currentOp) {\n      this.bulkOperation.s.currentOp = {};\n    }\n    this.bulkOperation.s.currentOp.upsert = true;\n    return this;\n  }\n  /** Specifies the collation for the query condition. */\n  collation(collation) {\n    if (!this.bulkOperation.s.currentOp) {\n      this.bulkOperation.s.currentOp = {};\n    }\n    this.bulkOperation.s.currentOp.collation = collation;\n    return this;\n  }\n  /** Specifies arrayFilters for UpdateOne or UpdateMany bulk operations. */\n  arrayFilters(arrayFilters) {\n    if (!this.bulkOperation.s.currentOp) {\n      this.bulkOperation.s.currentOp = {};\n    }\n    this.bulkOperation.s.currentOp.arrayFilters = arrayFilters;\n    return this;\n  }\n  /** Specifies hint for the bulk operation. */\n  hint(hint) {\n    if (!this.bulkOperation.s.currentOp) {\n      this.bulkOperation.s.currentOp = {};\n    }\n    this.bulkOperation.s.currentOp.hint = hint;\n    return this;\n  }\n}\nexports.FindOperators = FindOperators;\n/**\n * TODO(NODE-4063)\n * BulkWrites merge complexity is implemented in executeCommands\n * This provides a vehicle to treat bulkOperations like any other operation (hence \"shim\")\n * We would like this logic to simply live inside the BulkWriteOperation class\n * @internal\n */\nclass BulkWriteShimOperation extends operation_1.AbstractOperation {\n  constructor(bulkOperation, options) {\n    super(options);\n    this.bulkOperation = bulkOperation;\n  }\n  execute(server, session, callback) {\n    if (this.options.session == null) {\n      // An implicit session could have been created by 'executeOperation'\n      // So if we stick it on finalOptions here, each bulk operation\n      // will use this same session, it'll be passed in the same way\n      // an explicit session would be\n      this.options.session = session;\n    }\n    return executeCommands(this.bulkOperation, this.options, callback);\n  }\n}\n/** @public */\nclass BulkOperationBase {\n  /**\n   * Create a new OrderedBulkOperation or UnorderedBulkOperation instance\n   * @internal\n   */\n  constructor(collection, options, isOrdered) {\n    // determine whether bulkOperation is ordered or unordered\n    this.isOrdered = isOrdered;\n    const topology = (0, utils_1.getTopology)(collection);\n    options = options == null ? {} : options;\n    // TODO Bring from driver information in hello\n    // Get the namespace for the write operations\n    const namespace = collection.s.namespace;\n    // Used to mark operation as executed\n    const executed = false;\n    // Current item\n    const currentOp = undefined;\n    // Set max byte size\n    const hello = topology.lastHello();\n    // If we have autoEncryption on, batch-splitting must be done on 2mb chunks, but single documents\n    // over 2mb are still allowed\n    const usingAutoEncryption = !!(topology.s.options && topology.s.options.autoEncrypter);\n    const maxBsonObjectSize = hello && hello.maxBsonObjectSize ? hello.maxBsonObjectSize : 1024 * 1024 * 16;\n    const maxBatchSizeBytes = usingAutoEncryption ? 1024 * 1024 * 2 : maxBsonObjectSize;\n    const maxWriteBatchSize = hello && hello.maxWriteBatchSize ? hello.maxWriteBatchSize : 1000;\n    // Calculates the largest possible size of an Array key, represented as a BSON string\n    // element. This calculation:\n    //     1 byte for BSON type\n    //     # of bytes = length of (string representation of (maxWriteBatchSize - 1))\n    //   + 1 bytes for null terminator\n    const maxKeySize = (maxWriteBatchSize - 1).toString(10).length + 2;\n    // Final options for retryable writes\n    let finalOptions = Object.assign({}, options);\n    finalOptions = (0, utils_1.applyRetryableWrites)(finalOptions, collection.s.db);\n    // Final results\n    const bulkResult = {\n      ok: 1,\n      writeErrors: [],\n      writeConcernErrors: [],\n      insertedIds: [],\n      nInserted: 0,\n      nUpserted: 0,\n      nMatched: 0,\n      nModified: 0,\n      nRemoved: 0,\n      upserted: []\n    };\n    // Internal state\n    this.s = {\n      // Final result\n      bulkResult,\n      // Current batch state\n      currentBatch: undefined,\n      currentIndex: 0,\n      // ordered specific\n      currentBatchSize: 0,\n      currentBatchSizeBytes: 0,\n      // unordered specific\n      currentInsertBatch: undefined,\n      currentUpdateBatch: undefined,\n      currentRemoveBatch: undefined,\n      batches: [],\n      // Write concern\n      writeConcern: write_concern_1.WriteConcern.fromOptions(options),\n      // Max batch size options\n      maxBsonObjectSize,\n      maxBatchSizeBytes,\n      maxWriteBatchSize,\n      maxKeySize,\n      // Namespace\n      namespace,\n      // Topology\n      topology,\n      // Options\n      options: finalOptions,\n      // BSON options\n      bsonOptions: (0, bson_1.resolveBSONOptions)(options),\n      // Current operation\n      currentOp,\n      // Executed\n      executed,\n      // Collection\n      collection,\n      // Fundamental error\n      err: undefined,\n      // check keys\n      checkKeys: typeof options.checkKeys === 'boolean' ? options.checkKeys : false\n    };\n    // bypass Validation\n    if (options.bypassDocumentValidation === true) {\n      this.s.bypassDocumentValidation = true;\n    }\n  }\n  /**\n   * Add a single insert document to the bulk operation\n   *\n   * @example\n   * ```ts\n   * const bulkOp = collection.initializeOrderedBulkOp();\n   *\n   * // Adds three inserts to the bulkOp.\n   * bulkOp\n   *   .insert({ a: 1 })\n   *   .insert({ b: 2 })\n   *   .insert({ c: 3 });\n   * await bulkOp.execute();\n   * ```\n   */\n  insert(document) {\n    if (document._id == null && !shouldForceServerObjectId(this)) {\n      document._id = new bson_1.ObjectId();\n    }\n    return this.addToOperationsList(exports.BatchType.INSERT, document);\n  }\n  /**\n   * Builds a find operation for an update/updateOne/delete/deleteOne/replaceOne.\n   * Returns a builder object used to complete the definition of the operation.\n   *\n   * @example\n   * ```ts\n   * const bulkOp = collection.initializeOrderedBulkOp();\n   *\n   * // Add an updateOne to the bulkOp\n   * bulkOp.find({ a: 1 }).updateOne({ $set: { b: 2 } });\n   *\n   * // Add an updateMany to the bulkOp\n   * bulkOp.find({ c: 3 }).update({ $set: { d: 4 } });\n   *\n   * // Add an upsert\n   * bulkOp.find({ e: 5 }).upsert().updateOne({ $set: { f: 6 } });\n   *\n   * // Add a deletion\n   * bulkOp.find({ g: 7 }).deleteOne();\n   *\n   * // Add a multi deletion\n   * bulkOp.find({ h: 8 }).delete();\n   *\n   * // Add a replaceOne\n   * bulkOp.find({ i: 9 }).replaceOne({writeConcern: { j: 10 }});\n   *\n   * // Update using a pipeline (requires Mongodb 4.2 or higher)\n   * bulk.find({ k: 11, y: { $exists: true }, z: { $exists: true } }).updateOne([\n   *   { $set: { total: { $sum: [ '$y', '$z' ] } } }\n   * ]);\n   *\n   * // All of the ops will now be executed\n   * await bulkOp.execute();\n   * ```\n   */\n  find(selector) {\n    if (!selector) {\n      throw new error_1.MongoInvalidArgumentError('Bulk find operation must specify a selector');\n    }\n    // Save a current selector\n    this.s.currentOp = {\n      selector: selector\n    };\n    return new FindOperators(this);\n  }\n  /** Specifies a raw operation to perform in the bulk write. */\n  raw(op) {\n    if (op == null || typeof op !== 'object') {\n      throw new error_1.MongoInvalidArgumentError('Operation must be an object with an operation key');\n    }\n    if ('insertOne' in op) {\n      const forceServerObjectId = shouldForceServerObjectId(this);\n      if (op.insertOne && op.insertOne.document == null) {\n        // NOTE: provided for legacy support, but this is a malformed operation\n        if (forceServerObjectId !== true && op.insertOne._id == null) {\n          op.insertOne._id = new bson_1.ObjectId();\n        }\n        return this.addToOperationsList(exports.BatchType.INSERT, op.insertOne);\n      }\n      if (forceServerObjectId !== true && op.insertOne.document._id == null) {\n        op.insertOne.document._id = new bson_1.ObjectId();\n      }\n      return this.addToOperationsList(exports.BatchType.INSERT, op.insertOne.document);\n    }\n    if ('replaceOne' in op || 'updateOne' in op || 'updateMany' in op) {\n      if ('replaceOne' in op) {\n        if ('q' in op.replaceOne) {\n          throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n        }\n        const updateStatement = (0, update_1.makeUpdateStatement)(op.replaceOne.filter, op.replaceOne.replacement, {\n          ...op.replaceOne,\n          multi: false\n        });\n        if ((0, utils_1.hasAtomicOperators)(updateStatement.u)) {\n          throw new error_1.MongoInvalidArgumentError('Replacement document must not use atomic operators');\n        }\n        return this.addToOperationsList(exports.BatchType.UPDATE, updateStatement);\n      }\n      if ('updateOne' in op) {\n        if ('q' in op.updateOne) {\n          throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n        }\n        const updateStatement = (0, update_1.makeUpdateStatement)(op.updateOne.filter, op.updateOne.update, {\n          ...op.updateOne,\n          multi: false\n        });\n        if (!(0, utils_1.hasAtomicOperators)(updateStatement.u)) {\n          throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n        return this.addToOperationsList(exports.BatchType.UPDATE, updateStatement);\n      }\n      if ('updateMany' in op) {\n        if ('q' in op.updateMany) {\n          throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n        }\n        const updateStatement = (0, update_1.makeUpdateStatement)(op.updateMany.filter, op.updateMany.update, {\n          ...op.updateMany,\n          multi: true\n        });\n        if (!(0, utils_1.hasAtomicOperators)(updateStatement.u)) {\n          throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n        return this.addToOperationsList(exports.BatchType.UPDATE, updateStatement);\n      }\n    }\n    if ('deleteOne' in op) {\n      if ('q' in op.deleteOne) {\n        throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n      }\n      return this.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(op.deleteOne.filter, {\n        ...op.deleteOne,\n        limit: 1\n      }));\n    }\n    if ('deleteMany' in op) {\n      if ('q' in op.deleteMany) {\n        throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n      }\n      return this.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(op.deleteMany.filter, {\n        ...op.deleteMany,\n        limit: 0\n      }));\n    }\n    // otherwise an unknown operation was provided\n    throw new error_1.MongoInvalidArgumentError('bulkWrite only supports insertOne, updateOne, updateMany, deleteOne, deleteMany');\n  }\n  get bsonOptions() {\n    return this.s.bsonOptions;\n  }\n  get writeConcern() {\n    return this.s.writeConcern;\n  }\n  get batches() {\n    const batches = [...this.s.batches];\n    if (this.isOrdered) {\n      if (this.s.currentBatch) batches.push(this.s.currentBatch);\n    } else {\n      if (this.s.currentInsertBatch) batches.push(this.s.currentInsertBatch);\n      if (this.s.currentUpdateBatch) batches.push(this.s.currentUpdateBatch);\n      if (this.s.currentRemoveBatch) batches.push(this.s.currentRemoveBatch);\n    }\n    return batches;\n  }\n  execute(options, callback) {\n    callback = typeof callback === 'function' ? callback : typeof options === 'function' ? options : undefined;\n    return (0, utils_1.maybeCallback)(async () => {\n      options = options != null && typeof options !== 'function' ? options : {};\n      if (this.s.executed) {\n        throw new error_1.MongoBatchReExecutionError();\n      }\n      const writeConcern = write_concern_1.WriteConcern.fromOptions(options);\n      if (writeConcern) {\n        this.s.writeConcern = writeConcern;\n      }\n      // If we have current batch\n      if (this.isOrdered) {\n        if (this.s.currentBatch) this.s.batches.push(this.s.currentBatch);\n      } else {\n        if (this.s.currentInsertBatch) this.s.batches.push(this.s.currentInsertBatch);\n        if (this.s.currentUpdateBatch) this.s.batches.push(this.s.currentUpdateBatch);\n        if (this.s.currentRemoveBatch) this.s.batches.push(this.s.currentRemoveBatch);\n      }\n      // If we have no operations in the bulk raise an error\n      if (this.s.batches.length === 0) {\n        throw new error_1.MongoInvalidArgumentError('Invalid BulkOperation, Batch cannot be empty');\n      }\n      this.s.executed = true;\n      const finalOptions = {\n        ...this.s.options,\n        ...options\n      };\n      const operation = new BulkWriteShimOperation(this, finalOptions);\n      return (0, execute_operation_1.executeOperation)(this.s.collection.s.db.s.client, operation);\n    }, callback);\n  }\n  /**\n   * Handles the write error before executing commands\n   * @internal\n   */\n  handleWriteError(callback, writeResult) {\n    if (this.s.bulkResult.writeErrors.length > 0) {\n      const msg = this.s.bulkResult.writeErrors[0].errmsg ? this.s.bulkResult.writeErrors[0].errmsg : 'write operation failed';\n      callback(new MongoBulkWriteError({\n        message: msg,\n        code: this.s.bulkResult.writeErrors[0].code,\n        writeErrors: this.s.bulkResult.writeErrors\n      }, writeResult));\n      return true;\n    }\n    const writeConcernError = writeResult.getWriteConcernError();\n    if (writeConcernError) {\n      callback(new MongoBulkWriteError(writeConcernError, writeResult));\n      return true;\n    }\n    return false;\n  }\n}\nexports.BulkOperationBase = BulkOperationBase;\nObject.defineProperty(BulkOperationBase.prototype, 'length', {\n  enumerable: true,\n  get() {\n    return this.s.currentIndex;\n  }\n});\nfunction shouldForceServerObjectId(bulkOperation) {\n  var _a, _b;\n  if (typeof bulkOperation.s.options.forceServerObjectId === 'boolean') {\n    return bulkOperation.s.options.forceServerObjectId;\n  }\n  if (typeof ((_a = bulkOperation.s.collection.s.db.options) === null || _a === void 0 ? void 0 : _a.forceServerObjectId) === 'boolean') {\n    return (_b = bulkOperation.s.collection.s.db.options) === null || _b === void 0 ? void 0 : _b.forceServerObjectId;\n  }\n  return false;\n}\nfunction isInsertBatch(batch) {\n  return batch.batchType === exports.BatchType.INSERT;\n}\nfunction isUpdateBatch(batch) {\n  return batch.batchType === exports.BatchType.UPDATE;\n}\nfunction isDeleteBatch(batch) {\n  return batch.batchType === exports.BatchType.DELETE;\n}\nfunction buildCurrentOp(bulkOp) {\n  let {\n    currentOp\n  } = bulkOp.s;\n  bulkOp.s.currentOp = undefined;\n  if (!currentOp) currentOp = {};\n  return currentOp;\n}\n//# sourceMappingURL=common.js.map","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}