{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.MessageStream = void 0;\nconst stream_1 = require(\"stream\");\nconst error_1 = require(\"../error\");\nconst utils_1 = require(\"../utils\");\nconst commands_1 = require(\"./commands\");\nconst compression_1 = require(\"./wire_protocol/compression\");\nconst constants_1 = require(\"./wire_protocol/constants\");\nconst MESSAGE_HEADER_SIZE = 16;\nconst COMPRESSION_DETAILS_SIZE = 9; // originalOpcode + uncompressedSize, compressorID\nconst kDefaultMaxBsonMessageSize = 1024 * 1024 * 16 * 4;\n/** @internal */\nconst kBuffer = Symbol('buffer');\n/**\n * A duplex stream that is capable of reading and writing raw wire protocol messages, with\n * support for optional compression\n * @internal\n */\nclass MessageStream extends stream_1.Duplex {\n  constructor() {\n    let options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    super(options);\n    /** @internal */\n    this.isMonitoringConnection = false;\n    this.maxBsonMessageSize = options.maxBsonMessageSize || kDefaultMaxBsonMessageSize;\n    this[kBuffer] = new utils_1.BufferPool();\n  }\n  get buffer() {\n    return this[kBuffer];\n  }\n  _write(chunk, _, callback) {\n    this[kBuffer].append(chunk);\n    processIncomingData(this, callback);\n  }\n  _read( /* size */\n  ) {\n    // NOTE: This implementation is empty because we explicitly push data to be read\n    //       when `writeMessage` is called.\n    return;\n  }\n  writeCommand(command, operationDescription) {\n    // TODO: agreed compressor should live in `StreamDescription`\n    const compressorName = operationDescription && operationDescription.agreedCompressor ? operationDescription.agreedCompressor : 'none';\n    if (compressorName === 'none' || !canCompress(command)) {\n      const data = command.toBin();\n      this.push(Array.isArray(data) ? Buffer.concat(data) : data);\n      return;\n    }\n    // otherwise, compress the message\n    const concatenatedOriginalCommandBuffer = Buffer.concat(command.toBin());\n    const messageToBeCompressed = concatenatedOriginalCommandBuffer.slice(MESSAGE_HEADER_SIZE);\n    // Extract information needed for OP_COMPRESSED from the uncompressed message\n    const originalCommandOpCode = concatenatedOriginalCommandBuffer.readInt32LE(12);\n    // Compress the message body\n    (0, compression_1.compress)({\n      options: operationDescription\n    }, messageToBeCompressed, (err, compressedMessage) => {\n      if (err || !compressedMessage) {\n        operationDescription.cb(err);\n        return;\n      }\n      // Create the msgHeader of OP_COMPRESSED\n      const msgHeader = Buffer.alloc(MESSAGE_HEADER_SIZE);\n      msgHeader.writeInt32LE(MESSAGE_HEADER_SIZE + COMPRESSION_DETAILS_SIZE + compressedMessage.length, 0); // messageLength\n      msgHeader.writeInt32LE(command.requestId, 4); // requestID\n      msgHeader.writeInt32LE(0, 8); // responseTo (zero)\n      msgHeader.writeInt32LE(constants_1.OP_COMPRESSED, 12); // opCode\n      // Create the compression details of OP_COMPRESSED\n      const compressionDetails = Buffer.alloc(COMPRESSION_DETAILS_SIZE);\n      compressionDetails.writeInt32LE(originalCommandOpCode, 0); // originalOpcode\n      compressionDetails.writeInt32LE(messageToBeCompressed.length, 4); // Size of the uncompressed compressedMessage, excluding the MsgHeader\n      compressionDetails.writeUInt8(compression_1.Compressor[compressorName], 8); // compressorID\n      this.push(Buffer.concat([msgHeader, compressionDetails, compressedMessage]));\n    });\n  }\n}\nexports.MessageStream = MessageStream;\n// Return whether a command contains an uncompressible command term\n// Will return true if command contains no uncompressible command terms\nfunction canCompress(command) {\n  const commandDoc = command instanceof commands_1.Msg ? command.command : command.query;\n  const commandName = Object.keys(commandDoc)[0];\n  return !compression_1.uncompressibleCommands.has(commandName);\n}\nfunction processIncomingData(stream, callback) {\n  const buffer = stream[kBuffer];\n  const sizeOfMessage = buffer.getInt32();\n  if (sizeOfMessage == null) {\n    return callback();\n  }\n  if (sizeOfMessage < 0) {\n    return callback(new error_1.MongoParseError(`Invalid message size: ${sizeOfMessage}`));\n  }\n  if (sizeOfMessage > stream.maxBsonMessageSize) {\n    return callback(new error_1.MongoParseError(`Invalid message size: ${sizeOfMessage}, max allowed: ${stream.maxBsonMessageSize}`));\n  }\n  if (sizeOfMessage > buffer.length) {\n    return callback();\n  }\n  const message = buffer.read(sizeOfMessage);\n  const messageHeader = {\n    length: message.readInt32LE(0),\n    requestId: message.readInt32LE(4),\n    responseTo: message.readInt32LE(8),\n    opCode: message.readInt32LE(12)\n  };\n  const monitorHasAnotherHello = () => {\n    if (stream.isMonitoringConnection) {\n      // Can we read the next message size?\n      const sizeOfMessage = buffer.getInt32();\n      if (sizeOfMessage != null && sizeOfMessage <= buffer.length) {\n        return true;\n      }\n    }\n    return false;\n  };\n  let ResponseType = messageHeader.opCode === constants_1.OP_MSG ? commands_1.BinMsg : commands_1.Response;\n  if (messageHeader.opCode !== constants_1.OP_COMPRESSED) {\n    const messageBody = message.subarray(MESSAGE_HEADER_SIZE);\n    // If we are a monitoring connection message stream and\n    // there is more in the buffer that can be read, skip processing since we\n    // want the last hello command response that is in the buffer.\n    if (monitorHasAnotherHello()) {\n      return processIncomingData(stream, callback);\n    }\n    stream.emit('message', new ResponseType(message, messageHeader, messageBody));\n    if (buffer.length >= 4) {\n      return processIncomingData(stream, callback);\n    }\n    return callback();\n  }\n  messageHeader.fromCompressed = true;\n  messageHeader.opCode = message.readInt32LE(MESSAGE_HEADER_SIZE);\n  messageHeader.length = message.readInt32LE(MESSAGE_HEADER_SIZE + 4);\n  const compressorID = message[MESSAGE_HEADER_SIZE + 8];\n  const compressedBuffer = message.slice(MESSAGE_HEADER_SIZE + 9);\n  // recalculate based on wrapped opcode\n  ResponseType = messageHeader.opCode === constants_1.OP_MSG ? commands_1.BinMsg : commands_1.Response;\n  return (0, compression_1.decompress)(compressorID, compressedBuffer, (err, messageBody) => {\n    if (err || !messageBody) {\n      return callback(err);\n    }\n    if (messageBody.length !== messageHeader.length) {\n      return callback(new error_1.MongoDecompressionError('Message body and message header must be the same length'));\n    }\n    // If we are a monitoring connection message stream and\n    // there is more in the buffer that can be read, skip processing since we\n    // want the last hello command response that is in the buffer.\n    if (monitorHasAnotherHello()) {\n      return processIncomingData(stream, callback);\n    }\n    stream.emit('message', new ResponseType(message, messageHeader, messageBody));\n    if (buffer.length >= 4) {\n      return processIncomingData(stream, callback);\n    }\n    return callback();\n  });\n}\n//# sourceMappingURL=message_stream.js.map","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}