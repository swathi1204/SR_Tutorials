{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.GridFSBucket = void 0;\nconst error_1 = require(\"../error\");\nconst mongo_types_1 = require(\"../mongo_types\");\nconst utils_1 = require(\"../utils\");\nconst write_concern_1 = require(\"../write_concern\");\nconst download_1 = require(\"./download\");\nconst upload_1 = require(\"./upload\");\nconst DEFAULT_GRIDFS_BUCKET_OPTIONS = {\n  bucketName: 'fs',\n  chunkSizeBytes: 255 * 1024\n};\n/**\n * Constructor for a streaming GridFS interface\n * @public\n */\nclass GridFSBucket extends mongo_types_1.TypedEventEmitter {\n  constructor(db, options) {\n    super();\n    this.setMaxListeners(0);\n    const privateOptions = {\n      ...DEFAULT_GRIDFS_BUCKET_OPTIONS,\n      ...options,\n      writeConcern: write_concern_1.WriteConcern.fromOptions(options)\n    };\n    this.s = {\n      db,\n      options: privateOptions,\n      _chunksCollection: db.collection(privateOptions.bucketName + '.chunks'),\n      _filesCollection: db.collection(privateOptions.bucketName + '.files'),\n      checkedIndexes: false,\n      calledOpenUploadStream: false\n    };\n  }\n  /**\n   * Returns a writable stream (GridFSBucketWriteStream) for writing\n   * buffers to GridFS. The stream's 'id' property contains the resulting\n   * file's id.\n   *\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   */\n  openUploadStream(filename, options) {\n    return new upload_1.GridFSBucketWriteStream(this, filename, options);\n  }\n  /**\n   * Returns a writable stream (GridFSBucketWriteStream) for writing\n   * buffers to GridFS for a custom file id. The stream's 'id' property contains the resulting\n   * file's id.\n   */\n  openUploadStreamWithId(id, filename, options) {\n    return new upload_1.GridFSBucketWriteStream(this, filename, {\n      ...options,\n      id\n    });\n  }\n  /** Returns a readable stream (GridFSBucketReadStream) for streaming file data from GridFS. */\n  openDownloadStream(id, options) {\n    return new download_1.GridFSBucketReadStream(this.s._chunksCollection, this.s._filesCollection, this.s.options.readPreference, {\n      _id: id\n    }, options);\n  }\n  delete(id, callback) {\n    return (0, utils_1.maybeCallback)(async () => {\n      const {\n        deletedCount\n      } = await this.s._filesCollection.deleteOne({\n        _id: id\n      });\n      // Delete orphaned chunks before returning FileNotFound\n      await this.s._chunksCollection.deleteMany({\n        files_id: id\n      });\n      if (deletedCount === 0) {\n        // TODO(NODE-3483): Replace with more appropriate error\n        // Consider creating new error MongoGridFSFileNotFoundError\n        throw new error_1.MongoRuntimeError(`File not found for id ${id}`);\n      }\n    }, callback);\n  }\n  /** Convenience wrapper around find on the files collection */\n  find(filter, options) {\n    filter !== null && filter !== void 0 ? filter : filter = {};\n    options = options !== null && options !== void 0 ? options : {};\n    return this.s._filesCollection.find(filter, options);\n  }\n  /**\n   * Returns a readable stream (GridFSBucketReadStream) for streaming the\n   * file with the given name from GridFS. If there are multiple files with\n   * the same name, this will stream the most recent file with the given name\n   * (as determined by the `uploadDate` field). You can set the `revision`\n   * option to change this behavior.\n   */\n  openDownloadStreamByName(filename, options) {\n    let sort = {\n      uploadDate: -1\n    };\n    let skip = undefined;\n    if (options && options.revision != null) {\n      if (options.revision >= 0) {\n        sort = {\n          uploadDate: 1\n        };\n        skip = options.revision;\n      } else {\n        skip = -options.revision - 1;\n      }\n    }\n    return new download_1.GridFSBucketReadStream(this.s._chunksCollection, this.s._filesCollection, this.s.options.readPreference, {\n      filename\n    }, {\n      ...options,\n      sort,\n      skip\n    });\n  }\n  rename(id, filename, callback) {\n    return (0, utils_1.maybeCallback)(async () => {\n      const filter = {\n        _id: id\n      };\n      const update = {\n        $set: {\n          filename\n        }\n      };\n      const {\n        matchedCount\n      } = await this.s._filesCollection.updateOne(filter, update);\n      if (matchedCount === 0) {\n        throw new error_1.MongoRuntimeError(`File with id ${id} not found`);\n      }\n    }, callback);\n  }\n  drop(callback) {\n    return (0, utils_1.maybeCallback)(async () => {\n      await this.s._filesCollection.drop();\n      await this.s._chunksCollection.drop();\n    }, callback);\n  }\n  /** Get the Db scoped logger. */\n  getLogger() {\n    return this.s.db.s.logger;\n  }\n}\nexports.GridFSBucket = GridFSBucket;\n/**\n * When the first call to openUploadStream is made, the upload stream will\n * check to see if it needs to create the proper indexes on the chunks and\n * files collections. This event is fired either when 1) it determines that\n * no index creation is necessary, 2) when it successfully creates the\n * necessary indexes.\n * @event\n */\nGridFSBucket.INDEX = 'index';\n//# sourceMappingURL=index.js.map","map":null,"metadata":{},"sourceType":"script","externalDependencies":[]}